BASICS
ChemReaX: AP/IB Chem https://www.sciencebysimulation.com/chemreax/Faq.aspx

https://en.wikipedia.org/wiki/Computational_chemistry#Ab_initio_methods
https://en.wikipedia.org/wiki/Hartree%E2%80%93Fock_method (WOAH shrodinger)

https://en.wikipedia.org/wiki/Category:Computational_chemistry_software
https://en.wikipedia.org/wiki/Molecular_design_software

https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0331-1 Programming languages in chemistry: a review of HTML5/JavaScript
Several large, open source, JavaScript chemistry libraries are actively maintained, including the ChemDoodle Web Components [18], Kekule.js [19] and 3Dmol.js [20], to support the chemistry community.
JSmol, CanvasMol [53], ChemDoodle and TwirlyMol [54], Jolecule 

https://en.wikipedia.org/wiki/Cheminformatics
https://depth-first.com/articles/2019/05/01/javascript-for-cheminformatics-part-2/

https://github.com/GENESIS-EFRC/reaction-network


https://www.researchgate.net/post/Is-there-any-available-software-that-can-predict-simple-chemical-reactions
ChemAxon Reactor
Gaussian https://gaussian.com/ https://en.wikipedia.org/wiki/Gaussian_(software)
Hyperchem https://pubmed.ncbi.nlm.nih.gov/8333944/
Material Studio https://en.wikipedia.org/wiki/Materials_Studio
https://en.wikipedia.org/wiki/GAMESS_(US)

In chemistry, the law of mass action is the proposition that the rate of the chemical reaction is directly proportional to the product of the activities or concentrations of the reactants. https://en.wikipedia.org/wiki/Law_of_mass_action

https://en.wikipedia.org/wiki/Chemical_reaction_network_theory !!!!

https://people.chem.ucsb.edu/kahn/kalju/chem112L/public/minim_progs.html finds minimum distance for harmonic oscillator
https://arxiv.org/pdf/1908.06266.pdf

"
The following theorem provides an important class of generalized potential games. This
theorem is motivated from a recent theory on the generalized gradient flows of chemical
reactions [Mie11, MPR14]"

[Mie11] A. Mielke. A gradient structure for reaction–diffusion systems and for energy-drift-diffusion
systems. Nonlinearity, 24(4):1329–1346, mar 2011
[MPR14] A. Mielke, M. A. Peletier, and D. R. M. Renger. On the relation between gradient flows and the
large-deviation principle, with applications to markov chains and diffusion. Potential Analysis,
41(4):1293–1327, 2014

https://link.springer.com/article/10.1007/s10955-020-02663-4
Modeling of Chemical Reaction Systems with Detailed Balance Using Gradient Structures!!!

Newton–Raphson method = Newton's method for finding roots


This is an optimization algorithm that is like gradient descent in that it is
 first-order iterative optimization algorithm

Intuition behind why it's okay to iterate through equilibria like in interact.ts:

Consider a system. We know concentrations for substance A in the system, as well as substance B, substance C, substance D etc. We can consider the system to be a n-dimensional vector of all concentrations [A, B, C, ... Z], or also a point in space. When we take a "step" in interact.ts, we look at all of the concentrations and compare it to an equilibrium condition. Then, we adjust all of the concentrations such that we are guaranteed that the new concentration vector point is closer to the equilibrium condition than before.

Intuitively this works for only 1 equilibrium, because we can picture it as having only 1 valley and a ball rolling down that valley to the lowest potential energy until it finds the minimum/equilibrium. This is because we always know that the step will be going in the right direction. Where things get complicated is when we have multiple equilibria. Then, there will be multiple steps, and it's not clear if the two equilibria will result in an infinite loop, divergence, etc. We don't always know if 

For simplicity let's consider only 2 dimensions (only 2 concentrations.)

Conjecture: if it's 3d continuous, then steps are 'well-behaved' and multiple equilibria will converge.
Bad cases: 2 very parallel lines, when the solution is very far from the current state --> will take a LONG time.

We have an function with only 1 input variable. only 2 things are necessary to describe every state: the initial state S0 and the stepsize x. Let that function be Q(x) where x is the step size, and Q is the resultant Q value after a stepsize of size x is applied to initial state S0. (x can be negative.) Then we only need to minimize one variable

https://www.wolframalpha.com/input/?i=d%2Fds+%28A%2B3s%29%28B%2B5s%29%28C%2B7s%29%2F%28D-3s%29%2F%28E-5s%29%2F%28F-7s%29

Calculating the direct derivative is... hard. TODO: use numerical approximation